{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd6e47a3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "model = torch.load(\"beit_base_patch16_224_pt22k_ft22k.pth\", map_location='cpu')['model']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3f5729f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_keys = []\n",
    "nums = 0.\n",
    "for key in model.keys():\n",
    "    if \"num_batches_tracked\" not in key:\n",
    "        model_keys.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c673f37",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head.weight\n",
      "torch.Size([21841, 768])\n",
      "head.bias\n",
      "torch.Size([21841])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from mindspore import Tensor, dtype\n",
    "from mindspore import save_checkpoint\n",
    "from mindspore import Parameter\n",
    "weights = []\n",
    "prefix = \"model.\"\n",
    "for key in model_keys:\n",
    "    name2weight = {}\n",
    "    if \"bn\" in key or \"norm\" in key or \"ln\" in key:\n",
    "        if \"weight\" in key:\n",
    "            name2weight[\"name\"] = prefix + key.replace(\".weight\", \".gamma\")\n",
    "        elif \"bias\" in key:\n",
    "            name2weight[\"name\"] = prefix + key.replace(\".bias\", \".beta\")\n",
    "        elif \"mean\" in key:\n",
    "            name2weight[\"name\"] = prefix + key.replace(\"running_mean\", \"moving_mean\")\n",
    "        elif \"var\" in key:\n",
    "            name2weight[\"name\"] = prefix + key.replace(\"running_var\", \"moving_variance\")\n",
    "        name2weight[\"data\"] = Parameter(Tensor(model[key].numpy(), dtype.float32))\n",
    "        weights.append(name2weight)\n",
    "    elif \"qkv\" in key:\n",
    "        key_q = prefix + key.replace(\"qkv\", \"q\")\n",
    "        key_k = prefix + key.replace(\"qkv\", \"k\")\n",
    "        key_v = prefix + key.replace(\"qkv\", \"v\")\n",
    "        shape = model[key].shape[0]//3\n",
    "        weight = Parameter(Tensor(model[key].numpy(), dtype.float32))\n",
    "        weight_q = weight[:shape]\n",
    "        weight_k = weight[shape:shape*2]\n",
    "        weight_v = weight[shape*2:]\n",
    "        weights.append({\"name\":key_q, \"data\": weight_q})\n",
    "        weights.append({\"name\":key_k, \"data\": weight_k})\n",
    "        weights.append({\"name\":key_v, \"data\": weight_v})\n",
    "    elif \"q_bias\" in key or \"v_bias\" in key:\n",
    "        name2weight[\"name\"] = prefix + key.replace(\"_bias\", \".bias\")\n",
    "        name2weight[\"data\"] = Parameter(Tensor(model[key].numpy(), dtype.float32))\n",
    "        weights.append(name2weight)\n",
    "    elif \"head\" in key:\n",
    "        print(key)\n",
    "        print(model[key].shape)\n",
    "    else:\n",
    "        if \"relative_position_index\" in key:\n",
    "            dd = dtype.int32\n",
    "        if \"relative_position_index\" in key:\n",
    "            weight = Parameter(Tensor(model[key].numpy(), dtype.int32))\n",
    "        else:\n",
    "            weight = Parameter(Tensor(model[key].numpy(), dtype.float32))\n",
    "        key = prefix + key\n",
    "        weights.append({\"name\": key, \"data\": weight})\n",
    "save_checkpoint(weights, \"beit_base_patch16_224_pt22k_ft22k.ckpt\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "fd16a1c2e981052eaae61151b9525ae9913f1f0d16bca6b7e7be9e0f29d739d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}